{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c42974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium\n",
    "#!pip install geonamescache\n",
    "from helper import *\n",
    "import selenium\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import clear_output #clears output\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "API_Key ='irXxqVrXin1KsDRM9g6HdF8p8'\n",
    "API_Key_Secret = 'sLQvb8voyrTDz5S93vlt5jE5RlMi8xBuOQtSq2pgERe2QVawIC'\n",
    "\n",
    "Bearer_Token = 'AAAAAAAAAAAAAAAAAAAAACsVlAEAAAAADib49u9Asa6Hbts8UwBEdtc0dsk%3D1d8lVaySeRg1CpJQ6HDLSwK6Mj9wJiptj49PAdwMuvW95zJoar'\n",
    "\n",
    "Access_Token = '1122492746210660352-COptyz3RtF1AVokHw3027iOdbsZZl1'\n",
    "Access_Token_Secret = 'slfBz8pcgCrUmewZgSgVKsmIFhfCcFuinAx16q5eh1Vvr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28cf054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authorization of consumer key and consumer secret\n",
    "auth = tweepy.OAuthHandler(API_Key, API_Key_Secret)\n",
    "# set access to user's access key and access secret\n",
    "auth.set_access_token(Access_Token, Access_Token_Secret)\n",
    "# calling the api\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "Client = tweepy.Client(bearer_token=Bearer_Token) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e98b8e-64a1-484a-b232-72264422453b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### retrieving the tweets\n",
    "we will begin by saving the WOEIDs of each country in variables(The WOEID is a 32 bit adress of a place on earth, it's an odd system twitter adopted for some reason)\n",
    "\n",
    "we will then ask the API to get us 2000 tweets from each WOEID.\n",
    "we do this by giving the API a spacial query:\n",
    "\"plase:\" + WOEID = tells the API to only retrieve tweets from that location\n",
    "\n",
    "\"-filter:replies\" = tells the API to ignore tweets that are actually replies\n",
    "we ignore them since replies rarely get retweets and they basically filled our DataFrame with a lot of replies that have 0 retweets.\n",
    "\n",
    "\"-filter:retweets\" = we removed this since apperantly whenever someone retweets a tweets, it's concidered by twitter as it's own tweet. so what ended up happening is that we had several of the same tweet show up, it filled our Data Frame with duplicated.\n",
    "\n",
    "afterwards we activate a function we wrote called \"getAllTrends()\"\n",
    "the function uses the lenium to crawl into 'www.trends24.in' and get the trending topics in each country and every city in it(that is avalible)\n",
    "\n",
    "twitter's API has a function that allows us to get the trends in each area, however it has a very limited rate. So we used a third party website instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b5da9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Us secured\n",
      "canada secured\n",
      "UK secured\n",
      "kengooro land secured\n",
      "kengooroon't land secured\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#tweets_list = api.search_30_day(label = '30day',query = '#blender', fromDate = FROM_DATE,toDate = TO_DATE,maxResults = 10,tweet_mode = \"extended\")\n",
    "#tweets_list = tweepy.Cursor(api.search_tweets, \"biden\", count=100).items(100)\n",
    "\n",
    "\n",
    "start_date = datetime.datetime.now() - datetime.timedelta(days=14)\n",
    "end_date = start_date + datetime.timedelta(days=7)\n",
    "\n",
    "start_date = datetime.datetime.now()\n",
    "end_date = start_date + datetime.timedelta(days=1)\n",
    "'''\n",
    "\n",
    "# Search for tweets within the target countries\n",
    "usa = '96683cc9126741d1'\n",
    "canada = \"3376992a082d67c7\"\n",
    "great_britain = '6416b8512febefc9'\n",
    "Australia = '3f14ce28dc7c4566'\n",
    "new_zealand = \"0b039ce18ddf1cb9\"\n",
    "\n",
    "tweets_list = []\n",
    "#ALL_pages = tweepy.Cursor(api.search_tweets, q=\"since:{} until:{}\".format(start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")), lang=\"en\", tweet_mode=\"extended\", count = 100).pages(50)\n",
    "max_count_4_each_country = 2000\n",
    "\n",
    "#add usa\n",
    "tweets_list += tweepy.Cursor(api.search_tweets, q=\"place:\"+ usa + ' -filter:replies -filter:retweets', tweet_mode=\"extended\",include_entities=True,count = 100).items(max_count_4_each_country)\n",
    "print('Us secured')\n",
    "time.sleep(10)\n",
    "\n",
    "#add Canada\n",
    "tweets_list += tweepy.Cursor(api.search_tweets, q=\"place:\"+ canada + ' -filter:replies -filter:retweets', tweet_mode=\"extended\",include_entities=True,count = 100).items(max_count_4_each_country)\n",
    "print('canada secured')\n",
    "time.sleep(10)\n",
    "\n",
    "#add \"Great\" Britian\n",
    "tweets_list += tweepy.Cursor(api.search_tweets, q=\"place:\"+ great_britain + ' -filter:replies -filter:retweets', tweet_mode=\"extended\",include_entities=True,count = 100).items(max_count_4_each_country)\n",
    "print('UK secured')\n",
    "time.sleep(10)\n",
    "\n",
    "#add Australia\n",
    "tweets_list += tweepy.Cursor(api.search_tweets, q=\"place:\"+ Australia + ' -filter:replies -filter:retweets', tweet_mode=\"extended\",include_entities=True,count = 100).items(max_count_4_each_country)\n",
    "print('kengooro land secured')\n",
    "time.sleep(10)\n",
    "\n",
    "#add new zealand\n",
    "tweets_list += tweepy.Cursor(api.search_tweets, q=\"place:\"+ new_zealand + ' -filter:replies -filter:retweets', tweet_mode=\"extended\",include_entities=True,count = 100).items(max_count_4_each_country)\n",
    "print(\"kengooroon't land secured\")\n",
    "\n",
    "\n",
    "'''\n",
    "#return this if you are using pages again!!!!!\n",
    "for page in ALL_pages:\n",
    "    tweets_list.extend(page)\n",
    "#tweets_list = [t for t in tweets_list if t.in_reply_to_status_id == None]    \n",
    "'''\n",
    "\n",
    "trends = getAllTrends()#get trends\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5d9c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_list = [t for t in tweets_list]\n",
    "len(tweets_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee80cf7a-278a-4445-9646-a36d2e3ef85e",
   "metadata": {},
   "source": [
    "### crawling\n",
    "now the interseting part.\n",
    "\n",
    "firstly we will extract everything we need from each tweet\n",
    "1) the text\n",
    "2) the amount of words\n",
    "3) how many likes the tweet has\n",
    "4) how many retweets the tweet has\n",
    "5) is it a quote tweet\n",
    "6) the date the tweet was posted\n",
    "7) the ID of the tweet(this will be useful in the reextraction)\n",
    "8) the user's information\n",
    "\n",
    "then we will go over all users we have:\n",
    "because the twitter API likes to hide literally anything useful we will have to extract some information with brute force\n",
    "so we will use selenium to enter each users profile page\n",
    "\n",
    "using selenium and the API we extract he following:\n",
    "1) the screen name of the user(the name that is eunique to that spacific user)\n",
    "2) how many followers the user has\n",
    "3) how many people the user follows\n",
    "4) when the user joined(account age)\n",
    "5) how many tweets the user has tweeted in general\n",
    "6) is the user verified\n",
    "7) gender\n",
    "\n",
    "the API didn't give us the gender and age of the user.\n",
    "so we crawled into their profile and extracted it.\n",
    "\n",
    "in twitter it is very common to put the user's pronounce in their name,bio and or even location\n",
    "so we searched there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed7e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9800\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: timeout: Timed out receiving message from renderer: 300.000\n  (Session info: chrome=109.0.5414.74)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00A6F243]\n\t(No symbol) [0x009F7FD1]\n\t(No symbol) [0x008ED04D]\n\t(No symbol) [0x008DFC24]\n\t(No symbol) [0x008DFA5C]\n\t(No symbol) [0x008DE7E8]\n\t(No symbol) [0x008DEEF7]\n\t(No symbol) [0x008E7F08]\n\t(No symbol) [0x008F3455]\n\t(No symbol) [0x008F6766]\n\t(No symbol) [0x008DF2A1]\n\t(No symbol) [0x008F328F]\n\t(No symbol) [0x0094C8F2]\n\t(No symbol) [0x00938386]\n\t(No symbol) [0x0091163C]\n\t(No symbol) [0x0091269D]\n\tGetHandleVerifier [0x00D09A22+2655074]\n\tGetHandleVerifier [0x00CFCA24+2601828]\n\tGetHandleVerifier [0x00B18C0A+619850]\n\tGetHandleVerifier [0x00B17830+614768]\n\t(No symbol) [0x00A005FC]\n\t(No symbol) [0x00A05968]\n\t(No symbol) [0x00A05A55]\n\t(No symbol) [0x00A1051B]\n\tBaseThreadInitThunk [0x757500F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77317BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77317B8E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21508\\561561110.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;31m#opens the page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mscreen_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'screen_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mDRIVER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://twitter.com/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mscreen_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m#get the easy stuff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m         \"\"\"\n\u001b[1;32m--> 455\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"url\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    247\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: timeout: Timed out receiving message from renderer: 300.000\n  (Session info: chrome=109.0.5414.74)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00A6F243]\n\t(No symbol) [0x009F7FD1]\n\t(No symbol) [0x008ED04D]\n\t(No symbol) [0x008DFC24]\n\t(No symbol) [0x008DFA5C]\n\t(No symbol) [0x008DE7E8]\n\t(No symbol) [0x008DEEF7]\n\t(No symbol) [0x008E7F08]\n\t(No symbol) [0x008F3455]\n\t(No symbol) [0x008F6766]\n\t(No symbol) [0x008DF2A1]\n\t(No symbol) [0x008F328F]\n\t(No symbol) [0x0094C8F2]\n\t(No symbol) [0x00938386]\n\t(No symbol) [0x0091163C]\n\t(No symbol) [0x0091269D]\n\tGetHandleVerifier [0x00D09A22+2655074]\n\tGetHandleVerifier [0x00CFCA24+2601828]\n\tGetHandleVerifier [0x00B18C0A+619850]\n\tGetHandleVerifier [0x00B17830+614768]\n\t(No symbol) [0x00A005FC]\n\t(No symbol) [0x00A05968]\n\t(No symbol) [0x00A05A55]\n\t(No symbol) [0x00A1051B]\n\tBaseThreadInitThunk [0x757500F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77317BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77317B8E+238]\n"
     ]
    }
   ],
   "source": [
    "#search_tweets(q, *, geocode, lang, locale, result_type, count, until, since_id, max_id, include_entities)\n",
    "\n",
    "#user data\n",
    "\n",
    "DRIVER = webdriver.Chrome()#the chrome\n",
    "\n",
    "user_name = [];\n",
    "#location = [];\n",
    "\n",
    "city = [];\n",
    "country = [];\n",
    "age = [];\n",
    "gender = [];\n",
    "followers = [];\n",
    "following = [];\n",
    "verified = []\n",
    "joined = [] #when they joined\n",
    "acc_age = [] \n",
    "respectability = []\n",
    "tweet_count_user = []\n",
    "\n",
    "#tweet data\n",
    "tweet = [];\n",
    "word_count = [];\n",
    "likes = []\n",
    "retweet_count = []\n",
    "is_quote_status = []\n",
    "date = []\n",
    "tweet_id = []\n",
    "hashtags = []\n",
    "hashtags_count = []\n",
    "trending_for_area = []\n",
    "is_using_trend = []\n",
    "users = [];\n",
    "\n",
    "print('loading users')\n",
    "\n",
    "arr = []\n",
    "i = 1\n",
    "\n",
    "for t in tweets_list:\n",
    "    tweet.append(t.full_text);\n",
    "    \n",
    "    users.append(t.user);\n",
    "    \n",
    "    word_count.append(countWordsInString(t.full_text))\n",
    "    \n",
    "    likes.append( t.favorite_count)\n",
    "    \n",
    "    retweet_count.append(t.retweet_count)\n",
    "    \n",
    "    is_quote_status.append(t.is_quote_status)\n",
    "    \n",
    "    date.append(t.created_at.isoformat()[:10])\n",
    "    \n",
    "    tweet_id.append(t.id)\n",
    "    \n",
    "    \n",
    "        \n",
    "    city.append(t.place.name)\n",
    "    country.append( t.place.country)\n",
    "    \n",
    "    loc_trends = getTrendsByLoc(t.place.name,t.place.country,trends)\n",
    "    trending_for_area.append(loc_trends)\n",
    "    is_using_trend.append(areTrendUsed(t.full_text,loc_trends))\n",
    "    \n",
    "    ht = [t['text'] for t in t.entities['hashtags']]\n",
    "    ht_count = len(ht)\n",
    "    \n",
    "    if ht == []:\n",
    "        ht = np.nan\n",
    "        ht_count = 0\n",
    "        \n",
    "    hashtags.append(ht)\n",
    "    hashtags_count.append(ht_count)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "for x in users:\n",
    "    if i%26 == 0:\n",
    "        print(\"waiting\")\n",
    "        time.sleep(6)\n",
    "    j = x._json\n",
    "    \n",
    "    #opens the page\n",
    "    screen_name = j['screen_name']    \n",
    "    DRIVER.get('https://twitter.com/' + screen_name) \n",
    "    \n",
    "    #get the easy stuff\n",
    "    user_name.append(screen_name)\n",
    "    following.append(j['friends_count'])\n",
    "    followers.append(j['followers_count'])\n",
    "    \n",
    "    if(j['followers_count'] != 0):\n",
    "        respectability.append(float(j['friends_count']) / float(j['followers_count']))\n",
    "    else:\n",
    "        respectability.append(0)\n",
    "        \n",
    "    joined.append(x.created_at.isoformat()[:10])\n",
    "    acc_age.append(2023 - x.created_at.year + float(x.created_at.day)/12)\n",
    "    tweet_count_user.append(x.statuses_count)\n",
    "    verified.append(x.verified)\n",
    "    \n",
    "    \n",
    "    \n",
    "    tmp = getAge(DRIVER)#gets the age\n",
    "    if(tmp == 2023 - x.created_at.year): #checks if the age is the same as the accounts age\n",
    "        age.append(np.nan)\n",
    "    else:\n",
    "        age.append(tmp)\n",
    "    \n",
    "    \n",
    "    gender.append(getGender(j['description'],j['location'],j['name']))\n",
    "    \n",
    "    ##this part simply displays at the bottom how many profiles were checked\n",
    "    clear_output(wait=True) #clears the output\n",
    "    \n",
    "    i+=1\n",
    "    print(i)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "801a3498",
   "metadata": {},
   "outputs": [],
   "source": [
    "max = len(gender)\n",
    "\n",
    "for i in range(0,max):#rounds the account ages\n",
    "    acc_age[i] = round(acc_age[i],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084deef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData=['--------' for i in range(max)]\n",
    "dick = {\"name\":user_name[:max],\n",
    "        \"age\":age[:max],\n",
    "        'city':city[:max],\n",
    "        'country':country[:max],\n",
    "        \"gender\":gender[:max],\n",
    "        'acount age':acc_age[:max],\n",
    "        'total tweets': tweet_count_user[:max],\n",
    "        \"followers\":followers[:max],\n",
    "        \"following\":following[:max],\n",
    "        'respectability':respectability[:max],\n",
    "        'verified' : verified[:max],\n",
    "        'tweet':tweet[:max],\n",
    "        'likes':likes[:max],\n",
    "        'retweets':retweet_count[:max],\n",
    "        'word count': word_count[:max],\n",
    "        'is quote':is_quote_status[:max],\n",
    "        'hashtags':hashtags[:max],\n",
    "        'hashtag count':hashtags_count[:max],\n",
    "        'trending': trending_for_area[:max],\n",
    "        'using trends?':is_using_trend[:max],\n",
    "        'metaData':metaData[:max],\n",
    "        'join_date':joined[:max],\n",
    "        'date':date[:max],\n",
    "        'tweet id':tweet_id[:max]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame(dick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3e48e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>acount age</th>\n",
       "      <th>total tweets</th>\n",
       "      <th>followers</th>\n",
       "      <th>following</th>\n",
       "      <th>respectability</th>\n",
       "      <th>...</th>\n",
       "      <th>word count</th>\n",
       "      <th>is quote</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>hashtag count</th>\n",
       "      <th>trending</th>\n",
       "      <th>using trends?</th>\n",
       "      <th>metaData</th>\n",
       "      <th>join_date</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>streetsforall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Desert Hot Springs</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.5</td>\n",
       "      <td>4714</td>\n",
       "      <td>8223</td>\n",
       "      <td>137</td>\n",
       "      <td>0.016661</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[#TabooToken, Chargers, Herbert, Staley, Trevo...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2010-04-06</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>1614604722199228416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quersha_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.5</td>\n",
       "      <td>105862</td>\n",
       "      <td>1239</td>\n",
       "      <td>480</td>\n",
       "      <td>0.387409</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[#TabooToken, Chargers, Good Sunday, Herbert, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2010-05-18</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>1614604717782437893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gatitaconestres</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12600</td>\n",
       "      <td>333</td>\n",
       "      <td>189</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[#TabooToken, Chargers, Herbert, Staley, Trevo...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>1614604717727928320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheli_Smith</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upstate New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.8</td>\n",
       "      <td>13567</td>\n",
       "      <td>542</td>\n",
       "      <td>2121</td>\n",
       "      <td>3.913284</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>[shortfilmmaking, onset, cinema, tvfilm, movie...</td>\n",
       "      <td>7</td>\n",
       "      <td>[#TabooToken, Chargers, Herbert, Staley, Trevo...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2011-05-09</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>1614604716750536705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IgawaPastor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mission Viejo</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5113</td>\n",
       "      <td>150</td>\n",
       "      <td>398</td>\n",
       "      <td>2.653333</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[#TabooToken, Chargers, Herbert, Staley, Trevo...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2014-02-15</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>1614604716163342338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9794</th>\n",
       "      <td>arshadzackeriya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wellington City</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1022</td>\n",
       "      <td>289</td>\n",
       "      <td>482</td>\n",
       "      <td>1.667820</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "      <td>[DevOps, DevOpswithZack]</td>\n",
       "      <td>2</td>\n",
       "      <td>[Paula, Chargers, Paul Henry, #UFCVegas67, #su...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2011-05-24</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>1613851183457906688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>Ncookie98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.3</td>\n",
       "      <td>133568</td>\n",
       "      <td>121</td>\n",
       "      <td>516</td>\n",
       "      <td>4.264463</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[Paula, Chargers, Paul Henry, Perth, #UFCVegas...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2012-02-04</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>1613850481738280962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>erimedi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Christchurch City</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10015</td>\n",
       "      <td>190</td>\n",
       "      <td>376</td>\n",
       "      <td>1.978947</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[Paula, Chargers, Paul Henry, #UFCVegas67, #su...</td>\n",
       "      <td>True</td>\n",
       "      <td>--------</td>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>1613849326245261312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>auralorgasm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kapiti Coast District</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.8</td>\n",
       "      <td>56050</td>\n",
       "      <td>490</td>\n",
       "      <td>412</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[Paula, Chargers, Paul Henry, #UFCVegas67, #su...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>1613849166685560832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>Wiki_Pita</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.3</td>\n",
       "      <td>21218</td>\n",
       "      <td>1970</td>\n",
       "      <td>3482</td>\n",
       "      <td>1.767513</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[Paula, Chargers, Paul Henry, Perth, #UFCVegas...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2014-03-04</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>1613848372666044416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9799 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  age                   city        country  gender  \\\n",
       "0       streetsforall  NaN     Desert Hot Springs  United States     NaN   \n",
       "1            Quersha_  NaN              Charlotte  United States     NaN   \n",
       "2     Gatitaconestres  NaN          New Hampshire  United States     NaN   \n",
       "3         Cheli_Smith  NaN       Upstate New York  United States     NaN   \n",
       "4         IgawaPastor  NaN          Mission Viejo  United States     NaN   \n",
       "...               ...  ...                    ...            ...     ...   \n",
       "9794  arshadzackeriya  NaN        Wellington City    New Zealand     NaN   \n",
       "9795        Ncookie98  NaN               Auckland    New Zealand     NaN   \n",
       "9796          erimedi  NaN      Christchurch City    New Zealand     NaN   \n",
       "9797      auralorgasm  NaN  Kapiti Coast District    New Zealand     NaN   \n",
       "9798        Wiki_Pita  NaN               Auckland    New Zealand     NaN   \n",
       "\n",
       "      acount age  total tweets  followers  following  respectability  ...  \\\n",
       "0           13.5          4714       8223        137        0.016661  ...   \n",
       "1           14.5        105862       1239        480        0.387409  ...   \n",
       "2            5.0         12600        333        189        0.567568  ...   \n",
       "3           12.8         13567        542       2121        3.913284  ...   \n",
       "4           10.2          5113        150        398        2.653333  ...   \n",
       "...          ...           ...        ...        ...             ...  ...   \n",
       "9794        14.0          1022        289        482        1.667820  ...   \n",
       "9795        11.3        133568        121        516        4.264463  ...   \n",
       "9796         8.0         10015        190        376        1.978947  ...   \n",
       "9797         9.8         56050        490        412        0.840816  ...   \n",
       "9798         9.3         21218       1970       3482        1.767513  ...   \n",
       "\n",
       "      word count is quote                                           hashtags  \\\n",
       "0             34     True                                                NaN   \n",
       "1             10    False                                                NaN   \n",
       "2              4     True                                                NaN   \n",
       "3             17    False  [shortfilmmaking, onset, cinema, tvfilm, movie...   \n",
       "4              9    False                                                NaN   \n",
       "...          ...      ...                                                ...   \n",
       "9794          26    False                           [DevOps, DevOpswithZack]   \n",
       "9795           2    False                                                NaN   \n",
       "9796          11    False                                                NaN   \n",
       "9797           4     True                                                NaN   \n",
       "9798          11     True                                                NaN   \n",
       "\n",
       "      hashtag count                                           trending  \\\n",
       "0                 0  [#TabooToken, Chargers, Herbert, Staley, Trevo...   \n",
       "1                 0  [#TabooToken, Chargers, Good Sunday, Herbert, ...   \n",
       "2                 0  [#TabooToken, Chargers, Herbert, Staley, Trevo...   \n",
       "3                 7  [#TabooToken, Chargers, Herbert, Staley, Trevo...   \n",
       "4                 0  [#TabooToken, Chargers, Herbert, Staley, Trevo...   \n",
       "...             ...                                                ...   \n",
       "9794              2  [Paula, Chargers, Paul Henry, #UFCVegas67, #su...   \n",
       "9795              0  [Paula, Chargers, Paul Henry, Perth, #UFCVegas...   \n",
       "9796              0  [Paula, Chargers, Paul Henry, #UFCVegas67, #su...   \n",
       "9797              0  [Paula, Chargers, Paul Henry, #UFCVegas67, #su...   \n",
       "9798              0  [Paula, Chargers, Paul Henry, Perth, #UFCVegas...   \n",
       "\n",
       "      using trends?  metaData   join_date        date             tweet id  \n",
       "0             False  --------  2010-04-06  2023-01-15  1614604722199228416  \n",
       "1             False  --------  2010-05-18  2023-01-15  1614604717782437893  \n",
       "2             False  --------  2019-11-12  2023-01-15  1614604717727928320  \n",
       "3             False  --------  2011-05-09  2023-01-15  1614604716750536705  \n",
       "4             False  --------  2014-02-15  2023-01-15  1614604716163342338  \n",
       "...             ...       ...         ...         ...                  ...  \n",
       "9794          False  --------  2011-05-24  2023-01-13  1613851183457906688  \n",
       "9795          False  --------  2012-02-04  2023-01-13  1613850481738280962  \n",
       "9796           True  --------  2016-10-12  2023-01-13  1613849326245261312  \n",
       "9797          False  --------  2015-10-22  2023-01-13  1613849166685560832  \n",
       "9798          False  --------  2014-03-04  2023-01-13  1613848372666044416  \n",
       "\n",
       "[9799 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044d06c-c83d-4768-ad12-39a4d34042e0",
   "metadata": {},
   "source": [
    "The crawling is finished, we can close the browser and save the DataFrame to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75881c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVER.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb64968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data6.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
