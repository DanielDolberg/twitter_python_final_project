{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c42974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium\n",
    "#!pip install geonamescache\n",
    "from   helper import *\n",
    "import selenium\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from   bs4 import BeautifulSoup\n",
    "from   IPython.display import clear_output #clears output\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "API_Key = 'KEY'\n",
    "API_Key_Secret = 'KEY'\n",
    "\n",
    "Bearer_Token = 'KEY'\n",
    "\n",
    "Access_Token = 'KEY'\n",
    "Access_Token_Secret = 'KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28cf054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authorization of consumer key and consumer secret\n",
    "auth = tweepy.OAuthHandler(API_Key, API_Key_Secret)\n",
    "# set access to user's access key and access secret\n",
    "auth.set_access_token(Access_Token, Access_Token_Secret)\n",
    "# calling the api\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "Client = tweepy.Client(bearer_token=Bearer_Token) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e98b8e-64a1-484a-b232-72264422453b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### retrieving the tweets\n",
    "we will begin by saving the WOEIDs of each country in variables(The WOEID is a 32 bit adress of a place on earth, it's an odd system twitter adopted for some reason)\n",
    "\n",
    "we will then ask the API to get us 2000 tweets from each WOEID.\n",
    "we do this by giving the API a spacial query:\n",
    "\"plase:\" + WOEID = tells the API to only retrieve tweets from that location\n",
    "\n",
    "\"-filter:replies\" = tells the API to ignore tweets that are actually replies\n",
    "we ignore them since replies rarely get retweets and they basically filled our DataFrame with a lot of replies that have 0 retweets.\n",
    "\n",
    "\"-filter:retweets\" = we removed this since apperantly whenever someone retweets a tweets, it's concidered by twitter as it's own tweet. so what ended up happening is that we had several of the same tweet show up, it filled our Data Frame with duplicated.\n",
    "\n",
    "afterwards we activate a function we wrote called \"getAllTrends()\"\n",
    "the function uses the lenium to crawl into 'www.trends24.in' and get the trending topics in each country and every city in it(that is avalible)\n",
    "\n",
    "twitter's API has a function that allows us to get the trends in each area, however it has a very limited rate. So we used a third party website instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b5da9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Us secured\n",
      "canada secured\n",
      "UK secured\n",
      "kengooro land secured\n",
      "kengooroon't land secured\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#tweets_list = api.search_30_day(label = '30day',query = '#blender', fromDate = FROM_DATE,toDate = TO_DATE,maxResults = 10,tweet_mode = \"extended\")\n",
    "#tweets_list = tweepy.Cursor(api.search_tweets, \"biden\", count=100).items(100)\n",
    "\n",
    "\n",
    "start_date = datetime.datetime.now() - datetime.timedelta(days=14)\n",
    "end_date = start_date + datetime.timedelta(days=7)\n",
    "\n",
    "start_date = datetime.datetime.now()\n",
    "end_date = start_date + datetime.timedelta(days=1)\n",
    "'''\n",
    "\n",
    "# Search for tweets within the target countries\n",
    "usa = '96683cc9126741d1'\n",
    "canada = \"3376992a082d67c7\"\n",
    "great_britain = '6416b8512febefc9'\n",
    "Australia = '3f14ce28dc7c4566'\n",
    "new_zealand = \"0b039ce18ddf1cb9\"\n",
    "\n",
    "tweets_list = []\n",
    "#ALL_pages = tweepy.Cursor(api.search_tweets, q=\"since:{} until:{}\".format(start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")), lang=\"en\", tweet_mode=\"extended\", count = 100).pages(50)\n",
    "max_count_4_each_country = 2000\n",
    "\n",
    "\n",
    "#add usa\n",
    "tweets_list += tweepy.Cursor(api.search_tweets, q=\"place:\"+ usa + ' -filter:replies -filter:retweets',\n",
    "                             tweet_mode=\"extended\",\n",
    "                             include_entities=True,count = 100).items(max_count_4_each_country)\n",
    "\n",
    "print('Us secured')\n",
    "time.sleep(10)\n",
    "\n",
    "#add Canada\n",
    "tweets_list += tweepy.Cursor(api.search_tweets, q=\"place:\"+ canada + ' -filter:replies -filter:retweets', tweet_mode=\"extended\",include_entities=True,count = 100).items(max_count_4_each_country)\n",
    "print('canada secured')\n",
    "time.sleep(10)\n",
    "\n",
    "#add \"Great\" Britian\n",
    "tweets_list += tweepy.Cursor(api.search_tweets, q=\"place:\"+ great_britain + ' -filter:replies -filter:retweets', tweet_mode=\"extended\",include_entities=True,count = 100).items(max_count_4_each_country)\n",
    "print('UK secured')\n",
    "time.sleep(10)\n",
    "\n",
    "#add Australia\n",
    "tweets_list += tweepy.Cursor(api.search_tweets, q=\"place:\"+ Australia + ' -filter:replies -filter:retweets', tweet_mode=\"extended\",include_entities=True,count = 100).items(max_count_4_each_country)\n",
    "print('kengooro land secured')\n",
    "time.sleep(10)\n",
    "\n",
    "#add new zealand\n",
    "tweets_list += tweepy.Cursor(api.search_tweets, q=\"place:\"+ new_zealand + ' -filter:replies -filter:retweets', tweet_mode=\"extended\",include_entities=True,count = 100).items(max_count_4_each_country)\n",
    "print(\"kengooroon't land secured\")\n",
    "\n",
    "\n",
    "'''\n",
    "#return this if you are using pages again!!!!!\n",
    "for page in ALL_pages:\n",
    "    tweets_list.extend(page)\n",
    "#tweets_list = [t for t in tweets_list if t.in_reply_to_status_id == None]    \n",
    "'''\n",
    "\n",
    "trends = getAllTrends()#get trends\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5d9c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_list = [t for t in tweets_list]\n",
    "len(tweets_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee80cf7a-278a-4445-9646-a36d2e3ef85e",
   "metadata": {},
   "source": [
    "### crawling\n",
    "now the interseting part.\n",
    "\n",
    "firstly we will extract everything we need from each tweet\n",
    "1) the text\n",
    "2) the amount of words\n",
    "3) how many likes the tweet has\n",
    "4) how many retweets the tweet has\n",
    "5) is it a quote tweet\n",
    "6) the date the tweet was posted\n",
    "7) the ID of the tweet(this will be useful in the reextraction)\n",
    "8) the user's information\n",
    "\n",
    "then we will go over all users we have:\n",
    "because the twitter API likes to hide literally anything useful we will have to extract some information with brute force\n",
    "so we will use selenium to enter each users profile page\n",
    "\n",
    "using selenium and the API we extract he following:\n",
    "1) the screen name of the user(the name that is eunique to that spacific user)\n",
    "2) how many followers the user has\n",
    "3) how many people the user follows\n",
    "4) when the user joined(account age)\n",
    "5) how many tweets the user has tweeted in general\n",
    "6) is the user verified\n",
    "7) gender\n",
    "\n",
    "the API didn't give us the gender and age of the user.\n",
    "so we crawled into their profile and extracted it.\n",
    "\n",
    "in twitter it is very common to put the user's pronounce in their name,bio and or even location\n",
    "so we searched there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed7e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#search_tweets(q, *, geocode, lang, locale, result_type, count, until, since_id, max_id, include_entities)\n",
    "\n",
    "#user data\n",
    "\n",
    "DRIVER = webdriver.Chrome()#the chrome\n",
    "\n",
    "user_name = [];\n",
    "#location = [];\n",
    "\n",
    "city = [];\n",
    "country = [];\n",
    "age = [];\n",
    "gender = [];\n",
    "followers = [];\n",
    "following = [];\n",
    "verified = []\n",
    "joined = [] #when they joined\n",
    "acc_age = [] \n",
    "respectability = []\n",
    "tweet_count_user = []\n",
    "\n",
    "#tweet data\n",
    "tweet = [];\n",
    "word_count = [];\n",
    "likes = []\n",
    "retweet_count = []\n",
    "is_quote_status = []\n",
    "date = []\n",
    "tweet_id = []\n",
    "hashtags = []\n",
    "hashtags_count = []\n",
    "trending_for_area = []\n",
    "is_using_trend = []\n",
    "users = [];\n",
    "\n",
    "print('loading users')\n",
    "\n",
    "arr = []\n",
    "i = 1\n",
    "\n",
    "for t in tweets_list:\n",
    "    tweet.append(t.full_text);\n",
    "    \n",
    "    users.append(t.user);\n",
    "    \n",
    "    word_count.append(countWordsInString(t.full_text))\n",
    "    \n",
    "    likes.append( t.favorite_count)\n",
    "    \n",
    "    retweet_count.append(t.retweet_count)\n",
    "    \n",
    "    is_quote_status.append(t.is_quote_status)\n",
    "    \n",
    "    date.append(t.created_at.isoformat()[:10])\n",
    "    \n",
    "    tweet_id.append(t.id)\n",
    "    \n",
    "    \n",
    "        \n",
    "    city.append(t.place.name)\n",
    "    country.append( t.place.country)\n",
    "    \n",
    "    loc_trends = getTrendsByLoc(t.place.name,t.place.country,trends)\n",
    "    trending_for_area.append(loc_trends)\n",
    "    is_using_trend.append(areTrendUsed(t.full_text,loc_trends))\n",
    "    \n",
    "    ht = [t['text'] for t in t.entities['hashtags']]\n",
    "    ht_count = len(ht)\n",
    "    \n",
    "    if ht == []:\n",
    "        ht = np.nan\n",
    "        ht_count = 0\n",
    "        \n",
    "    hashtags.append(ht)\n",
    "    hashtags_count.append(ht_count)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "for x in users:\n",
    "    if i%26 == 0:\n",
    "        print(\"waiting\")\n",
    "        time.sleep(6)\n",
    "    j = x._json\n",
    "    \n",
    "    #opens the page\n",
    "    screen_name = j['screen_name']    \n",
    "    DRIVER.get('https://twitter.com/' + screen_name) \n",
    "    \n",
    "    #get the easy stuff\n",
    "    user_name.append(screen_name)\n",
    "    following.append(j['friends_count'])\n",
    "    followers.append(j['followers_count'])\n",
    "    \n",
    "    if(j['followers_count'] != 0):\n",
    "        respectability.append(float(j['friends_count']) / float(j['followers_count']))\n",
    "    else:\n",
    "        respectability.append(0)\n",
    "        \n",
    "    joined.append(x.created_at.isoformat()[:10])\n",
    "    acc_age.append(2023 - x.created_at.year + float(x.created_at.day)/12)\n",
    "    tweet_count_user.append(x.statuses_count)\n",
    "    verified.append(x.verified)\n",
    "    \n",
    "    \n",
    "    \n",
    "    tmp = getAge(DRIVER)#gets the age\n",
    "    if(tmp == 2023 - x.created_at.year): #checks if the age is the same as the accounts age\n",
    "        age.append(np.nan)\n",
    "    else:\n",
    "        age.append(tmp)\n",
    "    \n",
    "    \n",
    "    gender.append(getGender(j['description'],j['location'],j['name']))\n",
    "    \n",
    "    ##this part simply displays at the bottom how many profiles were checked\n",
    "    clear_output(wait=True) #clears the output\n",
    "    \n",
    "    i+=1\n",
    "    print(i)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "801a3498",
   "metadata": {},
   "outputs": [],
   "source": [
    "max = len(gender)\n",
    "\n",
    "for i in range(0,max):#rounds the account ages\n",
    "    acc_age[i] = round(acc_age[i],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084deef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData=['--------' for i in range(max)]\n",
    "dick = {\"name\":user_name[:max],\n",
    "        \"age\":age[:max],\n",
    "        'city':city[:max],\n",
    "        'country':country[:max],\n",
    "        \"gender\":gender[:max],\n",
    "        'acount age':acc_age[:max],\n",
    "        'total tweets': tweet_count_user[:max],\n",
    "        \"followers\":followers[:max],\n",
    "        \"following\":following[:max],\n",
    "        'respectability':respectability[:max],\n",
    "        'verified' : verified[:max],\n",
    "        'tweet':tweet[:max],\n",
    "        'likes':likes[:max],\n",
    "        'retweets':retweet_count[:max],\n",
    "        'word count': word_count[:max],\n",
    "        'is quote':is_quote_status[:max],\n",
    "        'hashtags':hashtags[:max],\n",
    "        'hashtag count':hashtags_count[:max],\n",
    "        'trending': trending_for_area[:max],\n",
    "        'using trends?':is_using_trend[:max],\n",
    "        'metaData':metaData[:max],\n",
    "        'join_date':joined[:max],\n",
    "        'date':date[:max],\n",
    "        'tweet id':tweet_id[:max]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame(dick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3e48e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>acount age</th>\n",
       "      <th>total tweets</th>\n",
       "      <th>followers</th>\n",
       "      <th>following</th>\n",
       "      <th>respectability</th>\n",
       "      <th>...</th>\n",
       "      <th>word count</th>\n",
       "      <th>is quote</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>hashtag count</th>\n",
       "      <th>trending</th>\n",
       "      <th>using trends?</th>\n",
       "      <th>metaData</th>\n",
       "      <th>join_date</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>giathxo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bethpage</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.3</td>\n",
       "      <td>3867</td>\n",
       "      <td>216</td>\n",
       "      <td>445</td>\n",
       "      <td>2.060185</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[Saka, #AVLARS, Zinchenko, Xhaka, #SaturdayMor...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2013-12-16</td>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>1626942985463013376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chenguanxi7979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[#gokingsgo, #AVLARS, Saka, Zinchenko, Mings, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2022-09-18</td>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>1626942982774525954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HolaArizona</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.7</td>\n",
       "      <td>3929</td>\n",
       "      <td>68</td>\n",
       "      <td>163</td>\n",
       "      <td>2.397059</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[#SmackDown, Saka, #AVLARS, Zinchenko, Xhaka, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>1626942982397267969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>420PandaNation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5502</td>\n",
       "      <td>2712</td>\n",
       "      <td>2478</td>\n",
       "      <td>0.913717</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[Saka, #AVLARS, Zinchenko, Xhaka, #SaturdayMor...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>1626942978760613889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JeffreyLuscombe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.5</td>\n",
       "      <td>342636</td>\n",
       "      <td>13792</td>\n",
       "      <td>11222</td>\n",
       "      <td>0.813660</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[Saka, #AVLARS, Zinchenko, Xhaka, #SaturdayMor...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2008-11-06</td>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>1626942973282770945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>LuisaLongone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1518</td>\n",
       "      <td>487</td>\n",
       "      <td>824</td>\n",
       "      <td>1.691992</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>[MIEExpertNZ, MIEE, MIEEFellow]</td>\n",
       "      <td>3</td>\n",
       "      <td>[#NZvENG, MySpace, napier, SMS 2FA, Chantelle,...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2014-06-23</td>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>1626295677088329728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>moanaduffy25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.4</td>\n",
       "      <td>127</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[#NZvENG, MySpace, napier, SMS 2FA, Chantelle,...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>1626295570699780096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>everylotchc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Christchurch City</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.4</td>\n",
       "      <td>33456</td>\n",
       "      <td>564</td>\n",
       "      <td>59</td>\n",
       "      <td>0.104610</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[#NZvENG, MySpace, napier, SMS 2FA, Chantelle,...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>1626295394639683584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>everylotakl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>38084</td>\n",
       "      <td>828</td>\n",
       "      <td>55</td>\n",
       "      <td>0.066425</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[#NZvENG, MySpace, napier, SMS 2FA, Chantelle,...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>1626295393003933697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>everylotwlg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wellington City</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.4</td>\n",
       "      <td>33587</td>\n",
       "      <td>1105</td>\n",
       "      <td>111</td>\n",
       "      <td>0.100452</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[#NZvENG, MySpace, napier, SMS 2FA, Chantelle,...</td>\n",
       "      <td>False</td>\n",
       "      <td>--------</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>1626295391296827395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  age               city        country  gender  \\\n",
       "0             giathxo  NaN           Bethpage  United States     NaN   \n",
       "1      chenguanxi7979  NaN        Los Angeles  United States     NaN   \n",
       "2         HolaArizona  NaN            Phoenix  United States     NaN   \n",
       "3      420PandaNation  NaN           Michigan  United States     NaN   \n",
       "4     JeffreyLuscombe  NaN    Fort Lauderdale  United States     NaN   \n",
       "...               ...  ...                ...            ...     ...   \n",
       "9995     LuisaLongone  NaN           Auckland    New Zealand     NaN   \n",
       "9996     moanaduffy25  NaN           Auckland    New Zealand     NaN   \n",
       "9997      everylotchc  NaN  Christchurch City    New Zealand     NaN   \n",
       "9998      everylotakl  NaN           Auckland    New Zealand     NaN   \n",
       "9999      everylotwlg  NaN    Wellington City    New Zealand     NaN   \n",
       "\n",
       "      acount age  total tweets  followers  following  respectability  ...  \\\n",
       "0           11.3          3867        216        445        2.060185  ...   \n",
       "1            2.5             3          1          3        3.000000  ...   \n",
       "2           11.7          3929         68        163        2.397059  ...   \n",
       "3            3.1          5502       2712       2478        0.913717  ...   \n",
       "4           15.5        342636      13792      11222        0.813660  ...   \n",
       "...          ...           ...        ...        ...             ...  ...   \n",
       "9995        10.9          1518        487        824        1.691992  ...   \n",
       "9996         3.4           127          2         12        6.000000  ...   \n",
       "9997         4.4         33456        564         59        0.104610  ...   \n",
       "9998         4.3         38084        828         55        0.066425  ...   \n",
       "9999         4.4         33587       1105        111        0.100452  ...   \n",
       "\n",
       "      word count is quote                         hashtags  hashtag count  \\\n",
       "0              5     True                              NaN              0   \n",
       "1              2    False                              NaN              0   \n",
       "2             57    False                              NaN              0   \n",
       "3             19    False                              NaN              0   \n",
       "4             16    False                              NaN              0   \n",
       "...          ...      ...                              ...            ...   \n",
       "9995           8     True  [MIEExpertNZ, MIEE, MIEEFellow]              3   \n",
       "9996          23    False                              NaN              0   \n",
       "9997           7    False                              NaN              0   \n",
       "9998           5    False                              NaN              0   \n",
       "9999          13    False                              NaN              0   \n",
       "\n",
       "                                               trending  using trends?  \\\n",
       "0     [Saka, #AVLARS, Zinchenko, Xhaka, #SaturdayMor...          False   \n",
       "1     [#gokingsgo, #AVLARS, Saka, Zinchenko, Mings, ...          False   \n",
       "2     [#SmackDown, Saka, #AVLARS, Zinchenko, Xhaka, ...          False   \n",
       "3     [Saka, #AVLARS, Zinchenko, Xhaka, #SaturdayMor...          False   \n",
       "4     [Saka, #AVLARS, Zinchenko, Xhaka, #SaturdayMor...          False   \n",
       "...                                                 ...            ...   \n",
       "9995  [#NZvENG, MySpace, napier, SMS 2FA, Chantelle,...          False   \n",
       "9996  [#NZvENG, MySpace, napier, SMS 2FA, Chantelle,...          False   \n",
       "9997  [#NZvENG, MySpace, napier, SMS 2FA, Chantelle,...          False   \n",
       "9998  [#NZvENG, MySpace, napier, SMS 2FA, Chantelle,...          False   \n",
       "9999  [#NZvENG, MySpace, napier, SMS 2FA, Chantelle,...          False   \n",
       "\n",
       "      metaData   join_date        date             tweet id  \n",
       "0     --------  2013-12-16  2023-02-18  1626942985463013376  \n",
       "1     --------  2022-09-18  2023-02-18  1626942982774525954  \n",
       "2     --------  2013-12-20  2023-02-18  1626942982397267969  \n",
       "3     --------  2022-09-25  2023-02-18  1626942978760613889  \n",
       "4     --------  2008-11-06  2023-02-18  1626942973282770945  \n",
       "...        ...         ...         ...                  ...  \n",
       "9995  --------  2014-06-23  2023-02-16  1626295677088329728  \n",
       "9996  --------  2022-07-29  2023-02-16  1626295570699780096  \n",
       "9997  --------  2020-01-17  2023-02-16  1626295394639683584  \n",
       "9998  --------  2020-01-16  2023-02-16  1626295393003933697  \n",
       "9999  --------  2020-01-17  2023-02-16  1626295391296827395  \n",
       "\n",
       "[10000 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044d06c-c83d-4768-ad12-39a4d34042e0",
   "metadata": {},
   "source": [
    "The crawling is finished, we can close the browser and save the DataFrame to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75881c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVER.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfb64968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data7.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
